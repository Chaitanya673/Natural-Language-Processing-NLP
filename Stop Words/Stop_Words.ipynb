{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "! pip install NLTK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: NLTK in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (3.3)\nRequirement already satisfied: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from NLTK) (1.11.0)\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk\nnltk.download('stopwords')",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package stopwords to /home/nbuser/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\nprint(set(stopwords.words('english')))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'his', 'theirs', 'nor', 'll', 'once', \"you're\", 'did', 'she', 'her', 'doing', 'until', 'm', 'yours', 'why', 'do', 'each', 's', 'which', \"don't\", 'haven', \"shan't\", 'can', 'couldn', 'd', 'our', 'him', \"you've\", 'most', 'before', 'had', 'if', 're', 'because', 'here', 'about', 'of', \"aren't\", 'who', 'than', 'such', 'any', 'only', 'other', \"that'll\", 'is', 'am', \"it's\", \"needn't\", 'didn', 'below', 'between', 'hers', 'yourselves', 'ain', 'on', 'wasn', 'having', 'so', 'by', 'you', 'herself', 'have', \"should've\", \"didn't\", 'whom', 'their', 'mustn', 'it', 'all', 'needn', 'yourself', 'mightn', \"mustn't\", 'ours', 'or', 'will', 'doesn', 'were', 'the', 'off', 'same', 'does', 'into', 'again', \"hadn't\", 'my', 'those', 'where', 'them', 'very', 'ma', 'its', 'been', 'me', 'but', 'no', 've', \"wouldn't\", 'then', 'too', 'how', \"you'll\", 'won', \"she's\", 'down', 'weren', 'shan', 'himself', 'for', 'i', 'to', 'while', 'over', 'are', 'against', 'both', 'further', 'just', \"you'd\", 'own', 'isn', 'what', 'myself', 'should', 'your', 'in', 'be', 'under', 't', 'shouldn', 'that', 'at', 'we', 'as', 'itself', 'a', 'during', 'an', 'and', 'from', 'few', \"hasn't\", \"won't\", 'with', 'he', \"doesn't\", \"shouldn't\", 'when', 'wouldn', 'has', 'hadn', 'up', \"mightn't\", 'now', 'out', 'more', 'aren', 'there', 'ourselves', \"wasn't\", 'o', 'being', \"haven't\", 'these', 'they', 'was', \"isn't\", 'after', 'above', \"weren't\", 'y', 'not', 'themselves', 'hasn', 'through', 'don', 'this', 'some', \"couldn't\"}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Read text file"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text_file = open(\"demo_text.txt\",'r')\nmy_text = text_file.read()\nprint(my_text)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Hi Learner! Welcome to NLP (Natural Language Processing) with Python. Here you will learn text mining and processing on natural language data. Are you aware about the Python basics? \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Normalize demo text by removing unuseful Characters\n\nHow can we normalize this text?\n\n• Remove punctuation\n\n• Remove capital letters and make all letters lowercase\n\n• Remove numbers\n\n• Remove Stop Words"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Remove Punctuation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re # Regular expression library\nimport string\n# Replace punctuations with a white space\nclean_text = re.sub('[%s]' % re.escape(string.punctuation), ' ', my_text)\nclean_text",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "'Hi Learner  Welcome to NLP  Natural Language Processing  with Python  Here you will learn text mining and processing on natural language data  Are you aware about the Python basics  '"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Make All Text Lowercase"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clean_text = clean_text.lower()\nclean_text",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "'hi learner  welcome to nlp  natural language processing  with python  here you will learn text mining and processing on natural language data  are you aware about the python basics  '"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Tokenization"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nltk.tokenize import word_tokenize\n\nword_tokens = word_tokenize(clean_text)\nprint(word_tokens)",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['hi', 'learner', 'welcome', 'to', 'nlp', 'natural', 'language', 'processing', 'with', 'python', 'here', 'you', 'will', 'learn', 'text', 'mining', 'and', 'processing', 'on', 'natural', 'language', 'data', 'are', 'you', 'aware', 'about', 'the', 'python', 'basics']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(word_tokens)",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "29"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### NLTK's Frequency Distribution Function FreqDist()"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from nltk.probability import FreqDist",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Count Words or Word Frequency"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "word_count = nltk.FreqDist(word_tokens)\nword_count",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "FreqDist({'natural': 2, 'language': 2, 'processing': 2, 'python': 2, 'you': 2, 'hi': 1, 'learner': 1, 'welcome': 1, 'to': 1, 'nlp': 1, ...})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# View top 5 most common words \nfdist_top = FreqDist.most_common(word_count, 5)\nfdist_top",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "[('natural', 2), ('language', 2), ('processing', 2), ('python', 2), ('you', 2)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### STOP WORDS"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stop_words = set(stopwords.words('english'))",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "filtered_sentence = []\n\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)\n        \nprint(filtered_sentence)",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['hi', 'learner', 'welcome', 'nlp', 'natural', 'language', 'processing', 'python', 'learn', 'text', 'mining', 'processing', 'natural', 'language', 'data', 'aware', 'python', 'basics']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(filtered_sentence)",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": "18"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Count Words or Word Frequency"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "word_count1 = nltk.FreqDist(filtered_sentence)\nword_count1",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 63,
          "data": {
            "text/plain": "FreqDist({'natural': 2, 'language': 2, 'processing': 2, 'python': 2, 'hi': 1, 'learner': 1, 'welcome': 1, 'nlp': 1, 'learn': 1, 'text': 1, ...})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# View top 5 most common words \nfdist_top = FreqDist.most_common(word_count1, 5)\nfdist_top",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "[('natural', 2), ('language', 2), ('processing', 2), ('python', 2), ('hi', 1)]"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}